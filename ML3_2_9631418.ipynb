{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML3_2_9631418.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cv4OcQij8tcD"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from scipy import stats\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from math import log,exp\n",
        "from sklearn import base"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQv53Fte9Jyt"
      },
      "source": [
        "test = pd.read_csv(\"/content/data_test.csv\",header=None)\n",
        "train = pd.read_csv(\"/content/data_train.csv\",header=None)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVv4y8ZG9ZQR",
        "outputId": "53aac8c5-f5f7-4672-e7ef-970321e1a481"
      },
      "source": [
        "print(test.shape)\n",
        "print(train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3498, 17)\n",
            "(7494, 17)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ub5gD8M9Aizn"
      },
      "source": [
        "## الف)\n",
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcWS_oMiAtOb"
      },
      "source": [
        "train1=train.copy()\n",
        "test1=test.copy()\n",
        "train1=train1.to_numpy()\n",
        "test1=test1.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx6KmCkJSh2N",
        "outputId": "71b3e5aa-4e21-4271-ec15-57293d39f6f6"
      },
      "source": [
        "print(test1.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3498, 17)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylKqXAZKCrnn"
      },
      "source": [
        "bootstrap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-yHZneiCtXq"
      },
      "source": [
        "#function returns a random sample with size m from dataframe (with replacement) in the form of data and taget\n",
        "def bootstrapSample(dataFrame):\n",
        "    randomIndices = np.random.randint(low = 0, high = len(dataFrame), size = len(dataFrame))\n",
        "    x=dataFrame[randomIndices]\n",
        "    data=x[:, :-1]\n",
        "    target=x[:,-1]\n",
        "    return data,target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4ue_FAkHlCO"
      },
      "source": [
        "aggregation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUZwpM4nGgUY",
        "outputId": "63fbca9d-4418-4070-eac7-25b853c63b05"
      },
      "source": [
        "#seperating data and labels in test set\n",
        "test_data=test1[: , :-1]\n",
        "test_label=test1[: , -1]\n",
        "\n",
        "#possible classes are 0,...,9\n",
        "possible_classes = list(dict.fromkeys(train1[:,-1]))\n",
        "\n",
        "#numpy array to store the result of all classifiers\n",
        "result=np.zeros((15,len(test_label)))\n",
        "for i in range(15):\n",
        "  train_data , train_label=bootstrapSample(train1)\n",
        "  decision_tree = DecisionTreeClassifier(max_depth=3,max_features=3)\n",
        "  decision_tree = decision_tree.fit(train_data, train_label)\n",
        "  #prediction result for each bootstrap data\n",
        "  result[i]=decision_tree.predict(test_data)\n",
        "#result for each data is the mode of all classifier's results\n",
        "predicted_label=stats.mode(result)[0]\n",
        "predicted_label=predicted_label.reshape(len(test_label))\n",
        "print(\"accuracy: \"+str(accuracy_score(y_true=test_label,y_pred=predicted_label)))\n",
        "print(confusion_matrix(y_true=test_label, y_pred=predicted_label, labels=range(len(possible_classes))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.6460834762721556\n",
            "[[324   2   6   0   0   0  31   0   0   0]\n",
            " [  0 151 206   3   1   0   3   0   0   0]\n",
            " [  0   4 343   2   0   0  13   2   0   0]\n",
            " [  0   7   1 327   1   0   0   0   0   0]\n",
            " [  0   5   0   0 343   0  16   0   0   0]\n",
            " [  2   7   9 118  30 166   3   0   0   0]\n",
            " [  2   0  15   2   6   0 306   5   0   0]\n",
            " [  1  54  14   2   0   2   0 291   0   0]\n",
            " [122   0  14   0   0  76  46  69   9   0]\n",
            " [  1  69   5 190  69   0   2   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPo4iYsjeTo7"
      },
      "source": [
        "## ب)\n",
        "AdaBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiEULY1Seavb"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX58zOERrz4F"
      },
      "source": [
        "train2=train.copy()\n",
        "test2=test.copy()\n",
        "train2=train2.to_numpy()\n",
        "test2=test2.to_numpy()"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDFW9KrhBJKC",
        "outputId": "b94af0c1-e9cc-4413-bc2a-f04ad930334e"
      },
      "source": [
        "a=np.array([1,2,3,4])\n",
        "a_pred=np.array([1,2,5,4])\n",
        "print((np.not_equal(a, a_pred)).astype(int) )\n"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1WBAUB12QHQ"
      },
      "source": [
        "def ada_boost_fit(X,y,num):\n",
        "  #X is the train data\n",
        "  #y is the train label\n",
        "  #num is the number of trees\n",
        "    classifiers=[]\n",
        "    alphas=[]\n",
        "    err=[]\n",
        "    N = len(y)\n",
        "    #initial w\n",
        "    w = np.array([1/N for i in range(N)])\n",
        "    #number of classes\n",
        "    k =10\n",
        "        \n",
        "    for m in range(num):\n",
        "            \n",
        "      Gm = base.clone(DecisionTreeClassifier(max_depth = 1)).\\\n",
        "                            fit(X,y,sample_weight=w).predict\n",
        "      classifiers.append(Gm)\n",
        "            \n",
        "      incorrect = Gm(X) != y\n",
        "      errM = np.average(incorrect,weights=w,axis=0)\n",
        "            \n",
        "      err.append(errM)\n",
        "\n",
        "      #for multiple classification      \n",
        "      BetaM = (np.log((1-errM)/errM)+np.log(k-1))\n",
        "      alphas.append(BetaM)\n",
        "\n",
        "      #updating w   \n",
        "      w *= np.exp(BetaM*incorrect*(w > 0))\n",
        "\n",
        "    return classifiers,err,alphas\n",
        " \n"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkaRg-vwoB55"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1grqSPiza3V",
        "outputId": "02233f9d-3775-495c-b64d-5b55363f9ed1"
      },
      "source": [
        "#possible_classes = list(dict.fromkeys(train1[:,-1]))\n",
        "possible_classes=[0,1,2,3,4,5,6,7,8,9]\n",
        "print(possible_classes)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TCd_AVWzAau"
      },
      "source": [
        "#function chooses the class thay has the highest betha in one row(could be a summation of a number of bethas)\n",
        "def voting(row):\n",
        "  probablity=np.zeros(len(possible_classes))\n",
        "  for p in range(len(possible_classes)):\n",
        "    for r in range(len(row)):\n",
        "      if row[r][0]==p:\n",
        "        probablity[p]=probablity[p]+row[r][1]\n",
        "  indices = np.where(probablity == probablity.max())\n",
        "  return indices[0][0]\n",
        "\n"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL33n-gxJsY9",
        "outputId": "0dd1f82c-60df-41b6-f74a-8f1b14630159"
      },
      "source": [
        "row=[(7,0.6),(3,0.5),(3,0.3)]\n",
        "print(voting(row))"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmeKd526ixRi"
      },
      "source": [
        "#predict using fitted model\n",
        "def predict(test_data,num,classifiers,alphas):\n",
        "  y_pred=[]\n",
        "  alphas=alphas/sum(alphas)\n",
        "  # Initialise dataframe with weak predictions for each observation\n",
        "  weak_preds = pd.DataFrame(index = range(len(test_data)), columns = range(num))\n",
        "  \n",
        "\n",
        "  # Predict class label for each weak classifier, weighted by alpha_m\n",
        "  for m in range(num):\n",
        "    y_pred_m=[]\n",
        "    ##print(classifiers[m])\n",
        "    #classifier m's result\n",
        "    tmp=classifiers[m](test_data)\n",
        "    ##print(tmp)\n",
        "    for i in range(len(test_data)):\n",
        "      #for the ith labe: classifier m's result and the related weight\n",
        "      y_pred_m.append((tmp[i],alphas[m]))\n",
        "    #print(y_pred_m)\n",
        "    weak_preds.iloc[:,m] = y_pred_m\n",
        "  #print(weak_preds)\n",
        "\n",
        "  # Estimate final predictions\n",
        "  for i in range(len(test_data)):\n",
        "    #print(weak_preds.iloc[i,:])\n",
        "    #find the class with the most weight\n",
        "    y_pred.append(voting(weak_preds.iloc[i,:]))\n",
        "  return y_pred"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEdQiDqDpWdN"
      },
      "source": [
        "#Get the error rates of each weak classifier.\n",
        "def error_rates(num, data, label,classifiers):\n",
        "  prediction_errors = []  \n",
        "  # Predict class label for each weak classifier\n",
        "  for m in range(num):\n",
        "    y_pred_m = classifiers[m](data)          \n",
        "    error_m = compute_error(label,y_pred_m, w_i = np.ones(len(label)))\n",
        "    prediction_errors.append(error_m)\n",
        "  return prediction_errors\n",
        "          "
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zlRCvuasLgw",
        "outputId": "2fbad4aa-b156-4b6c-a603-a95b0cf4bb71"
      },
      "source": [
        "clf,training_err,alphas=ada_boost_fit(train2[:,:-1],train2[:,-1],10)\n",
        "y_pred=predict(test2[:,:-1],10,clf,alphas)\n",
        "print(\"accuracy: \"+str(accuracy_score(y_true=test2[:,-1],y_pred=y_pred)))\n",
        "##print(error_rates(10,train2[:,:-1],train2[:,-1],clf))"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.49342481417953116\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEL5BTL_xV0f"
      },
      "source": [
        "## ج)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtSPYYDzyAIN"
      },
      "source": [
        "number of trees=5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdHJCYYdyDtS",
        "outputId": "bbc00f76-6c44-4b06-f58f-1f080b22356d"
      },
      "source": [
        "clf,training_err,alphas=ada_boost_fit(train2[:,:-1],train2[:,-1],5)\n",
        "y_pred=predict(test2[:,:-1],5,clf,alphas)\n",
        "print(\"accuracy: \"+str(accuracy_score(y_true=test2[:,-1],y_pred=y_pred)))\n"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.15208690680388792\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmiSVvW4yMWx"
      },
      "source": [
        "number of trees=20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hR70wErxyPdN",
        "outputId": "ab7598c4-24a2-4dd5-cad7-a380709d1d89"
      },
      "source": [
        "clf,training_err,alphas=ada_boost_fit(train2[:,:-1],train2[:,-1],20)\n",
        "y_pred=predict(test2[:,:-1],20,clf,alphas)\n",
        "print(\"accuracy: \"+str(accuracy_score(y_true=test2[:,-1],y_pred=y_pred)))\n"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.44882790165809033\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjwd10vJyVw4"
      },
      "source": [
        "number of trees=50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTmiqOnnyYz6",
        "outputId": "29fc10ff-a327-4e26-9698-ba854ce1296c"
      },
      "source": [
        "clf,training_err,alphas=ada_boost_fit(train2[:,:-1],train2[:,-1],50)\n",
        "y_pred=predict(test2[:,:-1],50,clf,alphas)\n",
        "print(\"accuracy: \"+str(accuracy_score(y_true=test2[:,-1],y_pred=y_pred)))\n"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.5877644368210406\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}